# {{ workflow_name }} - RunPod Serverless Endpoint

Generated by XiCON Serverless RunPod Automation System

## Overview

- **Workflow**: {{ workflow_name }}
- **Generated**: {{ timestamp }}
- **Input Type**: {{ input_type }}
- **Output Type**: {{ output_type }}

## Requirements

- Docker with NVIDIA GPU support
- NVIDIA Container Toolkit
- ~{{ total_model_size_gb }} GB disk space for models

## Quick Start

### Local Development

1. **Build and run with Docker Compose**:
```bash
docker-compose up --build
```

2. **Access ComfyUI**: Open http://localhost:8188

3. **Load the workflow**: Use the workflow JSON file

### RunPod Deployment

1. **Push to GitHub** (recommended):
```bash
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/your-username/your-repo.git
git push -u origin main
```

2. **Create RunPod Endpoint**:
   - Go to [RunPod Serverless](https://runpod.io/console/serverless)
   - Create new endpoint
   - Select "Custom Source" and enter your GitHub repo URL
   - Configure GPU type (recommended: A100/A40 for video generation)

3. **API Usage**:
```bash
curl -X POST "https://api.runpod.ai/v2/${ENDPOINT_ID}/run" \
  -H "Authorization: Bearer ${RUNPOD_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "input": {
      "workflow": <your-workflow-json>,
      "images": [
        {
          "name": "input_image.jpg",
          "image": "<base64-encoded-image>"
        }
      ]
    }
  }'
```

## Custom Nodes Used

{% for pack in custom_nodes %}
- **{{ pack.name }}**: {{ pack.repo }}
{% endfor %}

{% if unresolved_nodes %}
### Unresolved Nodes

The following nodes need manual installation:
{% for node in unresolved_nodes %}
- {{ node }}
{% endfor %}
{% endif %}

## Models

{% for model in models %}
- **{{ model.filename }}** ({{ model.size_gb }} GB)
  - Path: `{{ model.relative_path }}`
  - URL: {{ model.url }}
{% endfor %}

{% if unresolved_models %}
### Missing Model URLs

{% for model in unresolved_models %}
- {{ model }}
{% endfor %}
{% endif %}

## Input/Output

### Input
{{ input_description }}

### Output
{{ output_description }}

## Troubleshooting

### Build Failures

1. **Custom node installation fails**:
   - Check if the GitHub repo exists and is accessible
   - Some nodes may have additional dependencies

2. **Model download fails**:
   - Verify the HuggingFace URL is correct
   - Some models may require authentication

### Runtime Issues

1. **Out of Memory**:
   - Use a GPU with more VRAM (24GB+ recommended for video)
   - Enable model offloading in the workflow

2. **Slow Generation**:
   - Check GPU utilization
   - Consider using FP8 or FP16 models

## License

This generated configuration is provided as-is. Please check the licenses of:
- Individual custom nodes
- Model files
- ComfyUI itself

---

Generated with [XiCON Serverless RunPod Automation](https://github.com/your-repo)
